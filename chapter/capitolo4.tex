\chapter{L'implementazione in OpenCL}\label{capitolo4codice}
\vspace{4cm}


\section{Generatore dei task}
Al fine di poter comparare i risultati ottenuti in \cite{ilavarasan2007low} con i nostri, si è deciso di implementare un generatore di task con caratteristiche simili a quelle del paper, che fornisca in output una varietà di DAG su cui poter eseguire i test.
\\
Il generatore dipende da diversi parametri di input che sono:
\begin{itemize}
	\item{Number of tasks in the graph ($v$)}
	\item{Out degree ($\beta$)}
	\item{Shape parameter of a graph ($\alpha$)}
	\item{Communication to Computation Ratio (CCR)}
	\item{Range percentage of computation cost ($\eta$)}
\end{itemize}

In particolare, l'altezza del grafo è generata randomicamente a partire da una distribuzione uniforme con valore medio pari a $\frac{\sqrt{v}}{\alpha}$, mentre l'ampiezza viene calcolata per ogni livello a partire da una distribuzione uniforme con valore medio pari a $\sqrt{v}\times\alpha$.
In questo modo si può generare un grafo più o meno denso semplicemente modificando il parametro $\alpha$.

Il parametro CCR indica quanto i task sono impattanti dal punto di vista computazionale rispetto alla mole di dati che analizzano, se CCR è molto basso il costo computazionale è più alto rispetto alla quantità di dati trasmessi ai task successori pertanto l'applicazione può essere considerata ad alta intensità di calcolo, viceversa se CCR è alto l'applicazione trasmette molti dati tra i task ma non è molto pesante dal punto di vista computazionale.

Inoltre il parametro $\eta$ indica il grado di eterogeneità del sistema, cioè se ci sono differenze significative tra le prestazioni dei processori. Se $\eta$ è alto i costi dei task sui processori variano molto di processore in processore, viceversa se $\eta$ basso tutti i processori completeranno lo stesso task in tempi uguali. 

A partire da questo, il costo computazionale $W\ped{i,j}$ di ogni task $v\ped{i}$ su ogni processore $p\ped{j}$ è scelto randomicamente dall'intervallo $[W\ped{i}\times (1-\frac{\eta}{2}), W\ped{i}\times (1+\frac{\eta}{2})]$, dove $W\ped{i}$, costo medio della computazione del task $i$, è stato scelto casualmente da una distribuzione uniforme con estremi $0$ e $2 \times \text{Wdag}$, con Wdag costante del generatore che indica il costo medio di computazione dei task del grafo.

Infine $\beta$ indica quanti archi uscenti avrà in media ogni nodo.

Per i test, di cui parleremo nel \autoref{capitolo5risultati}, sono stati generati 100 dataset ognuno generato scegliendo casualmente ogni parametro tra i range di valori di seguito riportati:
\begin{itemize}
%	2^4, 2^5, 2^6, 2^7, 2^8, 2^9, 2^{10}, 2^{11}, 2^{12},
	\item{$v = \{2^{13}, 2^{14}, 2^{15}, 2^{16}, 2^{17}, 2^{18}, 2^{19}\}$}
	\item{$\beta =\{1, 2, 3, 4, 5\}$}
	\item{$\alpha = \{0.5, 1.0, 2.0\}$}
	\item{$CCR = \{0.1, 0.5, 1.0, 5.0, 10.0\}$}
	\item{$\eta = \{0.1, 0.5, 1.0\}$}
\end{itemize}

\section{Strutture dati}
Per mantenere in memoria le informazioni, riguardanti la rete, necessarie ad eseguire l'algoritmo si è usata una DAG o Direct Acyclic Graph, si tratta di un grafo orientato aciclico che permette di rappresentare le informazioni sulle dipendenze tra processi. Una dipendenza indica che un processo necessita di dati provenienti da un altro il quale deve necessariamente finire l'esecuzione prima che l'altro possa essere eseguito.
In particolare è stata implementata una DAG in cui i nodi rappresentano i processi e, gli archi, le dipendenze fra essi. Gli archi sono pesati e il peso indica il tempo necessario al trasferimento dei dati da un task ad un altro.

L'elenco dei task è stato mantenuto in memoria attraverso un array monodimensionale che associa ad ogni task (attraverso un identificativo numerico) il suo costo medio di esecuzione sui processori.

Per ragioni di ottimizzazione, invece che una singola matrice di adiacenza, sono state implementate tre matrici rettangolari, una che per ogni task tenesse traccia dei suoi predecessori, una speculare che tenesse traccia dei suoi successori e, infine, una che tenesse traccia dei pesi degli archi della prima matrice.

In ogni matrice rettangolare gli indici delle colonne rappresentano i task mentre le righe gli eventuali archi. Il numero di colonne è quindi fisso, mentre il numero di righe dipende dal massimo numero di successori e predecessori riscontrati all'interno della struttura dati. Inoltre, nelle prime due matrici all'interno delle singole celle vengono memorizzati gli identificativi del nodo all'altro estremo dell'arco, per questo è stato necessario mantenere una terza matrice con i pesi delle connessioni.

Questa scelta è stata fatta perché OpenCL non permette di implementare una lista di adiacenza sul device in quanto non è possibile allocare memoria dinamicamente all'interno dei kernel, né è possibile passare direttamente il puntatore ad un'eventuale lista in quanto, il puntatore ad un'area di memoria host, non avrebbe alcun senso per il device. Inoltre l'accesso alla memoria da parte di work-item con indici consecutivi è estremamente più efficiente quando i dati a cui accedono sono adiacenti e allineati, perché in questo modo è possibile sfruttare tutta la banda passante del BUS di memoria. 


\section{Fasi dell'algoritmo}
Al fine di implementare attraverso OpenCL una versione parallelizzata dell'algoritmo, sono state individuate 4 fasi:

\begin{enumerate}
	\item Ricerca degli entrypoint
	\item Calcolo dei livelli e dei ranghi
	\item Ordinamento dei task
	\item Selezione del processore
\end{enumerate}
Per le prime tre fasi è stato implementato un kernel OpenCL da eseguire in parallelo su GPU, mentre l'ultimo step viene eseguito serialmente.

\subsection{Ricerca degli entrypoint}
In questa fase si ricercano i task che non hanno nessun predecessore, questi verranno assegnati al livello 0 e da loro partirà una ricerca in ampiezza che calcolerà le metriche dei singoli task.

La ricerca di questi task è particolarmente efficiente in quanto basta controllare che la prima riga sia nulla, in questo caso il task non avrà predecessori che altrimenti avrebbero riempito la colonna a partire dalla prima riga.\\

\begin{lstlisting}[language=C++, caption={entry\_discover kernel},captionpos=b]
	kernel void entry_discover(const int n_nodes, global edge_t* restrict edges, global int* entrypoints)
	{
		int current_node_index = get_global_id(0);
		
		int matrixToArrayIndex = matrix_to_array_indexes(0, current_node_index, n_nodes);
		
		if (edges[matrixToArrayIndex] <= -1)
		entrypoints[current_node_index] = 1;
	}
\end{lstlisting}

\subsection{Calcolo dei livelli e dei ranghi}
Per ogni task si analizzano i suoi predecessori in modo da calcolare la metrica del nodo a partire dal parent che fornisce il rank più alto.
Il grado è calcolato a partire da tre proprietà:
\begin{itemize}
	\item Average Computation Cost (ACC): costo medio di computazione del task sui processori.
	\item Data Transfer Cost (DTC): quantità di dati da trasferire dal task a tutti i suoi successori.
	\item Rank of Predecessor Task (RPT): il grado più alto fra i predecessori del task.
\end{itemize}
Da cui:
\begin{equation}\label{Grado}
	rank(v\ped{i}) = round(ACC(v\ped{i}) + DTC(v\ped{i}) + RPT(v\ped{i}))
\end{equation}

Dopo aver calcolato il grado del nodo, si aggiungono tutti i suoi figli alla coda, in modo che possano essere analizzati al prossimo ciclo del kernel se tutti i predecessori sono già stati analizzati. Questo è possibile perché la coda è stata inizializzata, per ogni nodo, con il numero di predecessori. In questo modo ogni predecessore decrementa il valore in coda di ogni suo figlio subito dopo essere stato analizzato. Ad ogni ciclo vengono quindi estratti dalla coda solo i nodi con valore nullo, cioè i nodi per cui il grado di tutti i parent è già stato calcolato. La procedura termina quando tutti i nodi della rete sono stati analizzati. Per verificare la condizione di terminazione, è necessario che l'host esegua un kernel di riduzione che sia in grado di determinare se la coda è vuota o meno, questo passaggio è necessario perché, come abbiamo detto, OpenCL non assicura che tutti i workgroup siano in esecuzione contemporaneamente, per cui è necessario un orchestratore esterno che funga da sincronizzatore.

\newpage

\begin{lstlisting}[language=C++, caption={Codice host per il kernel compute\_metrics },captionpos=b]
	void ComputeMetrics::run_kernel(Graph<int>* DAG)
	{
		metrics_t* metrics = new metrics_t[metrics_len]; 
		for (int i = 0; i < metrics.length; i++) metrics[i] = metrics_t{ DAG->nodes[i],0,i};
		
		OCLBufferManager::SetMetrics(metrics);
		
		cl_uint n_compute_unit;
		cl_int err = clGetDeviceInfo(OCLManager::device, CL_DEVICE_MAX_COMPUTE_UNITS, sizeof(n_compute_unit), &n_compute_unit);
		cl_uint local_work_size = 8;
		cl_uint n_workgroup = n_compute_unit * local_work_size;
		cl_mem out =  clCreateBuffer(OCLManager::context, CL_MEM_READ_WRITE, n_workgroup * sizeof(cl_int));
		
		bool more_to_process = false;
		do{
			cl_event compute_metrics_evt_end = run_compute_metrics_kernel();
			more_to_process = reduce(DAG->len, OCLBufferManager::GetQueue(), out, n_workgroup, local_work_size, 1, &compute_metrics_evt_end);
		} while (more_to_process);
	}

	bool ComputeMetrics::reduce(int n_nodes, cl_mem to_reduce, cl_mem out, cl_int n_workgroup, cl_int local_work_size, cl_int num_events_to_wait, cl_event* to_wait) {		
		cl_event reduction_evt[2];
		reduction_evt[0] = run_reduce_kernel(n_nodes, n_workgroup, local_work_size, out, to_reduce, num_events_to_wait, to_wait);
		reduction_evt[1] = run_reduce_kernel(n_workgroup, 1, local_work_size, out, out, 1, &reduction_evt[0]);
		
		cl_event read_evt;
		int reduction_sum;
		clEnqueueReadBuffer(OCLManager::queue, out, CL_TRUE, 0, sizeof(reduction_sum), &reduction_sum, 1, reduction_evt + 1, &read_evt);
		
		return reduction_sum > 0;
	}
\end{lstlisting}

\begin{lstlisting}[language=C++, caption={compute\_metrics reduction kernel},captionpos=b]
	kernel void reduce_queue(int nquarts, global int * restrict out, global const int4 * restrict in,
	local int * restrict lmem)
	{
		int i = get_global_id(0);
		const int workitem = get_local_id(0);
		
		int acc = 0;
		
		const int4 zero_element = (int4)(0, 0, 0, 0);
		
		while (i < nquarts) {
			const int i1 = i +   get_global_size(0);
			const int i2 = i + 2*get_global_size(0);
			const int i3 = i + 3*get_global_size(0);
			
			int4 r0 = in[i];
			int4 r1 = (i1 < nquarts ? in[i1] : zero_element);
			int4 r2 = (i2 < nquarts ? in[i2] : zero_element);
			int4 r3 = (i3 < nquarts ? in[i3] : zero_element);
			
			int4 v = (r0 + r1) + (r2 + r3);
			acc += (v.x + v.y) + (v.z + v.w);
			i += 4*get_global_size(0);
		}
		lmem[workitem] = acc;
		
		int active = get_local_size(0)/2;
		while (active > 0) {
			barrier(CLK_LOCAL_MEM_FENCE);
			if (workitem < active) {
				acc += lmem[workitem+active];
				lmem[workitem] = acc;
			}
			active /= 2;
		}
		if (workitem == 0)
		out[get_group_id(0)] = acc;
	}
\end{lstlisting}

\begin{lstlisting}[language=C++, caption={compute\_metrics kernel},captionpos=b]
	kernel void compute_metrics(global int* restrict nodes, global int* queue_, global int* next_queue_, global edge_t* restrict edges, global edge_t* restrict edges_reverse, global edge_t* restrict edges_weights, volatile global metrics_tt* metriche, const int max_adj_dept, const int max_adj_reverse_dept, const int n_nodes)
	{
		int current_node_index = get_global_id(0);
		
		[...] //omissis of various security checks
		
		/* Calcolo del rank a partire dai predecessori */
		int ACC = nodes[current_node_index];
		for (int parentAdjIndex = 0; parentAdjIndex < max_adj_dept; j++) {
			matrixToArrayIndex = matrix_to_array_indexes(parentAdjIndex, current_node_index, n_nodes);
			int DTC = sum_all_in_column(edges_weights, node_index, n_nodes);
			int parent_index = edges[matrixToArrayIndex];
			if (parent_index >= 0){
				int RPT = metriche[parent_index].x;
				int weight_with_this_parent = DTC + RPT + ACC;
				int level_with_this_parent = metriche[parent_index].y + 1;
				metrics_with_this_parent = (int3)(weight_with_this_parent, level_with_this_parent, current_node_index);
				if (metrics_with_this_parent > metriche[current_node_index])
					metriche[current_node_index] = metrics_with_this_parent;
			}
		}
	
		/* Aggiunta dei successori alla coda */
		for (int j = 0; j < max_adj_reverse_dept; j++) {
			int matrixToArrayIndex = matrix_to_array_indexes(j, i, n_nodes);
			int child_index = edges_reverse[matrixToArrayIndex];
			if (child_index >= 0)
				atomic_dec(&next_queue_[child_index]);	
		}
	}
\end{lstlisting}

\subsection{Ordinamento dei task}
Una volta calcolato il grado di ogni task è possibile ordinare quest'ultimi in modo che la priorità sia data ai task di livello più basso e, all'interno di ogni livello, al processo con grado maggiore.
In caso di parità il task con ACC minore riceve una priorità più alta.

Per l'ordinamento è stato implementato un kernel che applicasse l'algoritmo parallelo Bitonic mergesort. L'implementazione è stata adeguata al codice a partire da quella presente in \cite{parallelsort}.

In questo caso il kernel viene lanciato diverse volte dall'host, ogni volta con parametri \textit{stride} e \textit{blocksize} diversi.\\

\begin{lstlisting}[language=C++, caption={Bitonic mergesort codice host},captionpos=b]
	for (unsigned int blocksize = limit; blocksize <= metrics_len; blocksize <<= 1) {
		for (unsigned int stride = blocksize / 2; stride > 0; stride >>= 1) {
			if (stride >= limit) {
				sort_task_evts_end = run_bitonic_sort_kernel(metrics_array_len, stride, blocksize);
			}
		}
	}
\end{lstlisting}

\begin{lstlisting}[language=C++, caption={bitonic\_mergesort kernel, source: \url{https://github.com/Gram21/GPUSorting}},captionpos=b]
	__kernel void bitonic_mergesort(const global int3* inArray, global int3* outArray, const uint size, const uint blocksize, const uint stride)
	{
		uint gid = get_global_id(0);
		uint clampedGID = gid & (size / 2 - 1);
		
		uint index = 2 * clampedGID - (clampedGID & (stride - 1));
		char dir = (clampedGID & (blocksize / 2)) == 0;
		
		int3 left = data[index];
		int3 right = data[index + stride];
		
		sort(&left, &right, dir);
		
		data[index] = left;
		data[index + stride] = right;
	}
\end{lstlisting}
\newpage
\begin{lstlisting}[language=C++, caption={Funzioni necessarie al kernel bitonic\_mergesort},captionpos=b]
	inline void sort(int3 *a, int3 *b, int dir) {
		if (gt(*a, *b) == dir) swap(a, b);
	}
	inline int gt (int3 V1, int3 V2){s
		return compare(V1, V2) > 0;
	}
	int compare (int3 V1, int3 V2){
		if(V1.y == V2.y){
			return (V1.x < V2.x) ? 1 : -1;
		}
		return (V1.y > V2.y) ? 1 : -1;
	}
\end{lstlisting}

\subsection{Selezione del processore}
A questo punto si scandiscono i task sulla base della loro priorità e, ogni task, viene associato al processore migliore, cioè quello che fornisce $EFT$ (Earliest Finish Time) minore. 
Dove $EFT$ è definita come segue:
\begin{displaymath}
	avail[j] := \text{prossimo istante in cui il processore $j$ è libero.}
\end{displaymath}
\begin{displaymath}
	C\ped{t,i} := \text{tempo necessario al trasferimento dei dati tra i task $t$ e $i$.} 
\end{displaymath}
\begin{displaymath}
	W\ped{i,j} := \text{costo computazionale del processo $i$ sul processore $j$.} 
\end{displaymath}
Da cui:
\begin{equation}\label{EST}
	EST(v\ped{i},p\ped{j}) = max(avail[j], max(AFT(v\ped{t}) + C\ped{t,i} : V\ped{t} \in pred(v\ped{i})))
\end{equation}
\begin{equation}\label{EFT}
	EFT(v\ped{i},p\ped{j}) = W\ped{i,j} + EST(v\ped{i},p\ped{j})
\end{equation}

A causa del fatto che il calcolo di queste metriche non dipende solo dai predecessori ma anche dal prossimo slot libero nei processori, si è deciso di non implementare una versione parallela dell'ultima fase dell'algoritmo. Riportiamo quindi il codice C++ dell'implementazione seriale.\\

\newpage

\begin{lstlisting}[language=C++, caption={Algoritmo di selezione del processore},captionpos=b]
	void ScheduleTasksOnProcessors(Graph<graphT> DAG, int n_nodes)
	{
		cl_int3* task_processor_assignment = new cl_int3[n_nodes];
		int* processorsNextSlotStart = new int[DAG->number_of_processors];
		for (int i = 0; i < metrics_len; i++)
		{
			int current_node = ordered_metrics[i].z; 
			int predecessor_with_max_aft, max_aft_of_predecessors, processor_for_max_aft_predecessor, weight_for_max_aft_predecessor;
			
			find_predecessor_with_max_eft(
				DAG, current_node, predecessor_with_max_aft, max_aft_of_predecessors, 
				processor_for_max_aft_predecessor, weight_for_max_aft_predecessor
			);
			
			int cost_of_predecessors_in_different_processors;
			handle_transfert_cost_beetwen_tasks(
				DAG, current_node, predecessor_with_max_aft, 
				cost_of_predecessors_in_different_processors
			);
			
			assign_task_to_processor(
				DAG, current_node, max_aft_of_predecessors, 
				processor_for_max_aft_predecessor, weight_for_max_aft_predecessor,
				cost_of_predecessors_in_different_processors
			);
			
			processorsNextSlotStart[task_processor_assignment[current_node].x] = task_processor_assignment[current_node].z;
		}
	}
\end{lstlisting}
\begin{lstlisting}[language=C++, caption={Funzione di calcolo del predecessore con EFT massimo},captionpos=b]
	inline void find_predecessor_with_max_eft(Graph<graphT> DAG, int current_node, int predecessor_with_max_aft, int cost_of_predecessors_in_different_processors) {
		for (int j = 0; j < DAG->max_parents_for_nodes; j++)
		{
			int currentParent = DAG->edges[matrix_to_array_indexes(j, current_node, DAG->len)];
			if (currentParent > -1) {
				int edge_weight_with_parent = DAG->predecessors[matrix_to_array_indexes(j, current_node, DAG->len)];
				int parentEFT = task_processor_assignment[currentParent].z + edge_weight_with_parent;
				if (parentEFT > max_aft_of_predecessors) {
					max_aft_of_predecessors = parentEFT;
					predecessor_with_max_aft = currentParent;
					processor_for_max_aft_predecessor = task_processor_assignment[currentParent].x;
					weight_for_max_aft_predecessor = edge_weight_with_parent;
				}
			}
		}
	}
\end{lstlisting}

\newpage

\begin{lstlisting}[language=C++, caption={Funzione di gestione del costo di trasferimento dati tra task},captionpos=b]
	inline void handle_transfert_cost_beetwen_tasks(Graph<graphT> DAG, int current_node, int predecessor_with_max_aft, int max_aft_of_predecessors, int processor_for_max_aft_predecessor, int weight_for_max_aft_predecessor) {
		for (int j = 0; j < DAG->max_parents_for_nodes; j++)
		{
			int currentParent = DAG->edges[matrix_to_array_indexes(j, current_node, DAG->len)];
			if (currentParent > -1 && currentParent != predecessor_with_max_aft) {
				cost_of_predecessors_in_different_processors = max(
				cost_of_predecessors_in_different_processors,
				task_processor_assignment[currentParent].z + DAG->predecessors[matrix_to_array_indexes(j, current_node, DAG->len)]
				);
			}
		}
	}
\end{lstlisting}
\begin{lstlisting}[language=C++, caption={Funzione che gestisce lo scheduling del task su un processore},captionpos=b]
	inline void assign_task_to_processor(Graph<graphT> DAG, int current_node, int max_aft_of_predecessors, int processor_for_max_aft_predecessor, int weight_for_max_aft_predecessor, int cost_of_predecessors_in_different_processors) {
		int eft_min = INT_MAX;
		int remaining_transfer_cost;
		for (int processor = 0; processor < DAG->number_of_processors; processor++) {
			int cost_of_predecessor_in_same_processor = 0;
			int cost_on_processor = DAG->costs[matrix_to_array_indexes(current_node, processor, DAG->number_of_processors)];
			if (processor_for_max_aft_predecessor == processor) {
				cost_of_predecessor_in_same_processor = weight_for_max_aft_predecessor;
			}
			remaining_transfer_cost = max(max_aft_of_predecessors - cost_of_predecessor_in_same_processor, cost_of_predecessors_in_different_processors);
			
			int est = max(processorsNextSlotStart[processor], remaining_transfer_cost);
			int eft = est + cost_on_processor;
			if (eft < eft_min) {
				eft_min = eft;
				task_processor_assignment[current_node] = cl_int3{ processor, est, eft };
			}
		}
	}
\end{lstlisting}

NOTA: Il codice sorgente integrale può essere trovato al seguente indirizzo: \citeurl{codice}

\section{Ottimizzazioni}
Nel corso dello sviluppo sono stati tentati diversi approcci d'ottimizzazione, inizialmente la DAG era stata implementata sfruttando una classica matrice di adiacenza, ma i tempi necessari alla scoperta dei successori e predecessori di ogni nodo erano troppo elevati, si è allora tentato di ridurre i tempi sfruttando la matrice trasposta in modo da sfruttare al meglio la località dei dati e quindi gli eventuali cache hit, ma anche questo approccio non ha migliorato le prestazioni quanto si ci aspettava.

Si è allora passati alle matrici rettangolari e, inoltre, si è implementata una versione vettorizzata del kernel \textit{compute\_metrics} che analizzasse n-uple di nodi invece che singoli elementi.
Queste due modifiche hanno reso i tempi di runtime dell'implementazione parallela confrontabili con quelli presenti nel paper\cite{ilavarasan2007low} che, tuttavia, analizza solo dataset di piccola entità.
Per dataset di molti nodi invece, come vedremo nel prossimo capitolo, si nota un vantaggio considerevole della GPU rispetto alla CPU in termini di prestazioni.\\

\begin{lstlisting}[language=C++, caption={compute\_metrics\_vectorized8 kernel},captionpos=b]
	kernel void compute_metrics_vectorized8(const global int* restrict nodes, global int8* restrict queue_, const int n_nodes, const global edge_t* restrict edges, const global edge_t* restrict edges_reverse, const global edge_t* restrict edges_weights, global metrics_tt* metriche, const int max_adj_dept, const int max_adj_reverse_dept)
	{
		local int something_changed;
		int something_changed_for_me;
		int work_item_local_index = get_local_id(0);
		
		[...] //omissis of various security checks
		
		do {
			if (work_item_local_index == 0)
			something_changed = 0;
			
			if (!work_item_outside_range)
			something_changed_for_me = compute_metrics_vectorized8_internal(nodes, queue_, n_nodes, edges, edges_reverse, edges_weights, metriche, max_adj_dept, max_adj_reverse_dept);
			
			if (something_changed_for_me)
			something_changed = 1;
			
			barrier(CLK_LOCAL_MEM_FENCE);
		} while (something_changed > 0);
	}
\end{lstlisting}
\newpage
\begin{lstlisting}[language=C++, caption={compute\_metrics\_vectorized8 kernel internal function},captionpos=b]
bool compute_metrics_vectorized8_internal(const global int* restrict nodes, global int8* restrict queue_, const global edge_t* restrict edges, const global edge_t* restrict edges_reverse, const global edge_t* restrict edges_weights, global int3* metriche, const int max_adj_dept, const int max_adj_reverse_dept, const int n_nodes)
{
	int work_item = get_global_id(0);
	int something_changed = false;
	
	[...] //omissis of various security checks

	int8 nodes8 = queue_[work_item];
	int8 indexes_to_analyze_vec = (nodes8 == 0);
	global int* _nodes = &(queue_[work_item]);
	
	if(nodes8.s0 == 0) atomic_dec(&(_nodes[0]));
	if(nodes8.s1 == 0) atomic_dec(&(_nodes[1]));
	[...]
	if(nodes8.s7 == 0) atomic_dec(&(_nodes[7]));
	
	int4 any_to_analyze_in_quartet = indexes_to_analyze_vec.s0123 + indexes_to_analyze_vec.s4567;
	int2 any_to_analyze_in_couple = any_to_analyze_in_quartet.s01 + any_to_analyze_in_quartet.s23;
	int any_to_analyze = any_to_analyze_in_couple.s0 + any_to_analyze_in_couple.s1;
	if(any_to_analyze == 0)return something_changed;
	
	int node_index;
	if (indexes_to_analyze_vec.s0 == -1){
		node_index = work_item * 8;
		something_changed |= compute_metrics(work_item, node_index, nodes, queue_, n_nodes, edges, edges_reverse, edges_weights, metriche, max_adj_dept, max_adj_reverse_dept);
	}
	if (indexes_to_analyze_vec.s1 == -1){
		node_index = work_item * 8+1;
		something_changed |= compute_metrics(work_item, node_index, nodes, queue_, n_nodes, edges, edges_reverse, edges_weights, metriche, max_adj_dept, max_adj_reverse_dept);
	}
	[...]
	if (indexes_to_analyze_vec.s7 == -1){
		node_index = work_item * 8+7;
		something_changed |= compute_metrics(work_item, node_index, nodes, queue_, n_nodes, edges, edges_reverse, edges_weights, metriche, max_adj_dept, max_adj_reverse_dept);
	}
	
	return something_changed;
}
\end{lstlisting}
\newpage
\begin{lstlisting}[language=C++, caption={compute\_metrics\_vectorized8 kernel internal function},captionpos=b]
	bool compute_metrics(int workitem, int node_index, const global int* restrict nodes, global int8* restrict queue_, const int n_nodes, const global edge_t* restrict edges, const global edge_t* restrict edges_reverse, const global edge_t* restrict edges_weights, global metrics_tt* metriche, const int max_adj_dept, const int max_adj_reverse_dept){
		bool something_changed = false;
		int matrixToArrayIndex;
		int DTC = 0; 
		for (int j = 0; j < max_adj_reverse_dept; j++) {
			int matrixToArrayIndex = matrix_to_array_indexes(j, node_index, n_nodes);
			if(edges_weights[matrixToArrayIndex] > -1){
				DTC += edges_weights[matrixToArrayIndex];
			}
		}
		
		int ACC = nodes[node_index];
		metrics_tt metrics_with_this_parent;
		metrics_tt best_metrics_for_parent = (metrics_tt)(DTC + ACC, 0, ACC);
		
		/* Calcolo del rank a partire dai predecessori */
		for (int j = 0; j < max_adj_dept; j++) {
			int parent = j;
			matrixToArrayIndex = matrix_to_array_indexes(parent, node_index, n_nodes);
			int parentIndex = edges[matrixToArrayIndex];
			metrics_tt parent_metric = metriche[parentIndex];
			if (parentIndex >= 0) {
				int weight_with_this_parent = DTC + parent_metric.x + ACC;
				int level_with_this_parent = parent_metric.y + 1;
				metrics_with_this_parent = (metrics_tt)(weight_with_this_parent, level_with_this_parent, node_index);
				if (metrics_with_this_parent > best_metrics_for_parent)
					best_metrics_for_parent = metrics_with_this_parent;
			}
		}
		metriche[node_index] = best_metrics_for_parent;
		
		/* Aggiunta dei successori alla coda */
		for (int child = 0; child < max_adj_reverse_dept; j++) {
			matrixToArrayIndex = matrix_to_array_indexes(child, node_index, n_nodes);
			int childIndex = edges_reverse[matrixToArrayIndex];
			
			if (childIndex >= 0) {
				int globalIndexStart = child / 8;
				int localIndex = childIndex - globalIndexStart * 8;
				global int* four_next_nodes = &(queue_[globalIndexStart]);
				atomic_dec(&(four_next_nodes[childIndex - globalIndexStart * 8]));
				something_changed = true;
			}
		}
		return something_changed;
	}
\end{lstlisting}
\newpage
\section{Costo computazionale}
\label{analisicomputazionale}
La complessità di questa implementazione è $O(n)$ per la ricerca degli entrypoint, $O(n \cdot max(max\_adj\_dept, max\_adj\_reverse\_dept))$ per il calcolo delle metriche e $O(n\ log\ n)$ per l'ordinamento, dove $n$ è il numero di nodi mentre $max\_adj\_dept$ e $max\_adj\_reverse\_dept$ sono rispettivamente il massimo numero di successori e predecessori che un nodo può avere.

In definitiva, l'algoritmo ha complessità $O(n^{2})$ nel caso in cui il grafo sia denso, e $O(n \cdot log\ n)$ nel caso in cui $max(max\_adj\_dept, max\_adj\_reverse\_dept) \ll n$.